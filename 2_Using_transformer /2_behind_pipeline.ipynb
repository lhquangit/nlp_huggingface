{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.32.0-py3-none-any.whl (7.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/quan/anaconda3/envs/torch/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.15.1\n",
      "  Using cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/quan/anaconda3/envs/torch/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/quan/anaconda3/envs/torch/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2023.8.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
      "Requirement already satisfied: requests in /home/quan/anaconda3/envs/torch/lib/python3.11/site-packages (from transformers) (2.28.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm>=4.27\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Collecting fsspec\n",
      "  Using cached fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/quan/anaconda3/envs/torch/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/quan/anaconda3/envs/torch/lib/python3.11/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/quan/anaconda3/envs/torch/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/quan/anaconda3/envs/torch/lib/python3.11/site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/quan/anaconda3/envs/torch/lib/python3.11/site-packages (from requests->transformers) (2022.12.7)\n",
      "Installing collected packages: tokenizers, safetensors, tqdm, regex, pyyaml, fsspec, huggingface-hub, transformers\n",
      "Successfully installed fsspec-2023.6.0 huggingface-hub-0.16.4 pyyaml-6.0.1 regex-2023.8.8 safetensors-0.3.3 tokenizers-0.13.3 tqdm-4.66.1 transformers-4.32.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongquan/Projects/3_nlp-huggingface/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598048329353333},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\n",
    "    [\n",
    "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "        \"I hate this so much!\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong ví dụ trên Pipeline, đã nhóm 3 bước lại với nhau: tiền xử lý data, đưa data qua mô hình và hậu xử lý"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing with a tokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quy trình**\n",
    "- Tách input thành words, subwords, symbols(như dấu câu) được gọi là các token\n",
    "- Mapping mỗi token thành số (int)\n",
    "- Thêm các đầu vào bổ sung"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tất cả quá trình tiền xử lý cần được thực hiện giống như khi model được train, nên đầu tiên cấn tải thông tin đó từ Model Hub\n",
    "- Sử dụng class AutoTokenizer với phương thức from_pretrained(), tokenizer sẽ được lưu vào cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau khi có tokenizer, chúng tôi có thể trực tiếp chuyển các câu của mình tới nó và chúng tôi sẽ trả lại một từ điển sẵn sàng cung cấp cho mô hình! Điều duy nhất còn lại phải làm là chuyển đổi danh sách input ID thành tensor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để chỉ định loại tensor mà chúng ta muốn trả về (PyTorch, TensorFlow hoặc NumPy), chúng ta sử dụng đối số return_tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
      "          2607,  2026,  2878,  2166,  1012,   102],\n",
      "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much!\",\n",
    "]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output là 1 dictionary bao gồm:\n",
    "- input_ids: Là 1 tensor gôm 2 hàng số nguyên, mỗi hàng tương ứng với 1 câu\n",
    "- attention_mask: Giải thích sau"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going through the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModel.from_pretrained(checkpoint)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Output được gọi là hidden state (trạng thái ẩn), còn được gọi là features (tính năng).\n",
    "- Với mỗi input, output sẽ là  1 high-dimensional vector "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A high-dimensional vector?**\n",
    "\n",
    "Vector output của Transformer thường lớn. nó có 3 chiều\n",
    "- Batch size: Số lượng sequences được xử lý tại cùng 1 thời điểm (Trong ví dụ là 2)\n",
    "- Sequence length: Độ dài của biểu diễn số trong 1 chuỗi (Trong ví dụ là 16)\n",
    "- Hidden size: Chiều của mỗi vector input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16, 768])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(inputs[\"input_ids\"])\n",
    "print(outputs.last_hidden_state.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model heads: Making sense out of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocessing the output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bản thân các giá trị nhận được dưới dạng đầu ra từ mô hình của mình không nhất thiết phải có ý nghĩa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BaseModelOutput' object has no attribute 'logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(outputs\u001b[39m.\u001b[39;49mlogits)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BaseModelOutput' object has no attribute 'logits'"
     ]
    }
   ],
   "source": [
    "print(outputs.logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
